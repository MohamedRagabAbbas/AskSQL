{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --q unstructured langchain\n",
    "%pip install --q \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "# from langchain_community.document_loaders import OnlinePDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "txt_path = 'schema.txt'  \n",
    "\n",
    "if not os.path.exists(txt_path):\n",
    "    print('The text file does not exist. Please upload the text file to the path:', txt_path)\n",
    "else:\n",
    "    with open(txt_path, 'r') as file:\n",
    "        data = file.read()\n",
    "    print(\"Text file loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --q chromadb\n",
    "%pip install --q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(page_content=data)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = splitter.split_documents([document])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED               \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    Less than a second ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 19/19 [00:58<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "vector_databse = Chroma.from_documents(\n",
    "    documents = texts,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\", trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(\"./\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./\", config=config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_model(text):\n",
    "    if not isinstance(text, str):\n",
    "        if hasattr(text, \"to_string\"):  \n",
    "            text = text.to_string()  \n",
    "        else:\n",
    "            raise TypeError(\"Input to chain_model must be a string or a StringPromptValue with a to_string method.\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    ids = model.generate(**inputs, max_length=inputs['input_ids'].shape[-1] + 100)\n",
    "    output = tokenizer.decode(ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_databse.as_retriever(),\n",
    "    chain_model,\n",
    "    QUERY_PROMPT,\n",
    ")\n",
    "\n",
    "Rag_Template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(Rag_Template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chain_model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Answer the question based ONLY on the following context:\n",
      "[Document(page_content='PRODUCT_ID NUMBER(38,0),\\n\\tRATING_STARS NUMBER(38,0),\\n\\tprimary key (ID)\\n);\\ncreate or replace TABLE USER_ACTIONS (\\n\\tACTION_TIME TIMESTAMP_NTZ(9),\\n\\tUSER_ID NUMBER(38,0),\\n\\tACTION VARCHAR(255)\\n);\\ncreate or replace TABLE USER_LOGINS (\\n\\tLOGIN_TIME TIMESTAMP_NTZ(9),\\n\\tUSER_ID NUMBER(38,0)\\n);\\ncreate or replace TABLE ZIP_CODES (\\n\\tZIP_CODE VARCHAR(10),\\n\\tSTATE VARCHAR(255)\\n);'), Document(page_content='CAMPAIGNNAME VARCHAR(16777216),\\n  CLICKS NUMBER(38,0),\\n  COST FLOAT,\\n  DATE TIMESTAMP_NTZ(9),\\n  DESTINATIONURL VARCHAR(16777216),\\n  IMPRESSIONS NUMBER(38,0)\\n);\\ncreate or replace TABLE EVENTS (\\n  ID NUMBER(38,0),\\n  CAMPAIGN VARCHAR(16777216),\\n  COUPONID NUMBER(38,0),\\n  DEVICE VARCHAR(16777216),\\n  KEY VARCHAR(16777216),\\n  KID NUMBER(38,0),\\n  EVENTNAME VARCHAR(16777216),\\n  ORIGIN VARCHAR(16777216),\\n  SESSIONID NUMBER(38,0),\\n  SESSIONORIGIN VARCHAR(16777216),\\n  STORESLUG VARCHAR(16777216),'), Document(page_content='create or replace TABLE AFFILIATE_NETWORKS (\\n  ID NUMBER(38,0),\\n  NAME VARCHAR(16777216),\\n  PARTNERID NUMBER(38,0)\\n);\\ncreate or replace TABLE AFFILIATE_PROGRAM_STORES (\\n  ID NUMBER(38,0),\\n  AFFILIATENETWORKID NUMBER(38,0),\\n  PROGRAM VARCHAR(16777216),\\n  STOREID NUMBER(38,0)\\n);\\ncreate or replace TABLE COUPONS (\\n  ID NUMBER(38,0),\\n  ACCOUNTID NUMBER(38,0),\\n  AFFILIATENETWORKID NUMBER(38,0),\\n  CODE VARCHAR(16777216),\\n  COUPONID NUMBER(38,0),\\n  COUPONTYPE FLOAT,\\n  CREATIONDATE TIMESTAMP_NTZ(9),'), Document(page_content='COUPONID NUMBER(38,0),\\n  COUPONTYPE FLOAT,\\n  CREATIONDATE TIMESTAMP_NTZ(9),\\n  DESCRIPTION VARCHAR(16777216),\\n  EDITORNOTE VARCHAR(16777216),\\n  EXPIRATIONDATE TIMESTAMP_NTZ(9),\\n  ISDIKED BOOLEAN,\\n  ISEXCLUSIVE BOOLEAN,\\n  ISFEATURED BOOLEAN,\\n  ISNOTWORKING BOOLEAN,\\n  ISSPECIALSALE BOOLEAN,\\n  ISSTAFFPICK BOOLEAN,\\n  ISSTOREWIDE BOOLEAN,\\n  ISUNRELIABLE BOOLEAN,\\n  LASTCHECKEDDATE TIMESTAMP_NTZ(9),\\n  LASTMODIFIEDDATE TIMESTAMP_NTZ(9),\\n  SMALLTITLE VARCHAR(16777216),\\n  STARTDATE TIMESTAMP_NTZ(9),'), Document(page_content='ISSYNCED BOOLEAN,\\n  LASTUPDATE TIMESTAMP_NTZ(9),\\n  ORIGIN VARCHAR(16777216),\\n  SUBSCRIBEDATE TIMESTAMP_NTZ(9),\\n  USERID NUMBER(38,0)\\n);\\ncreate or replace TABLE NEWSLETTER_AREAS_OF_INTEREST (\\n  ID NUMBER(38,0),\\n  ACTIVESTATUS NUMBER(38,0),\\n  CREATIONDATE TIMESTAMP_NTZ(9),\\n  GENERAL BOOLEAN,\\n  ISOPTIN BOOLEAN,\\n  LASTUPDATE TIMESTAMP_NTZ(9),\\n  NEWSLETTERID NUMBER(38,0),\\n  STOREID NUMBER(38,0)\\n);\\ncreate or replace TABLE NEWSVIEWS (\\n  ID NUMBER(38,0),\\n  EMAIL VARCHAR(16777216),'), Document(page_content='NEWSLETTERID NUMBER(38,0),\\n  STOREID NUMBER(38,0),\\n  STORENAME VARCHAR(16777216),\\n  TIME TIMESTAMP_NTZ(9),\\n  URL VARCHAR(16777216)\\n);\\ncreate or replace TABLE NEWSLETTERS (\\n  ID NUMBER(38,0),\\n  CHANNEL NUMBER(38,0),\\n  CREATIONDATE TIMESTAMP_NTZ(9),\\n  EMAIL VARCHAR(16777216),\\n  HASH VARCHAR(16777216),\\n  HASREPORTEDSPAM BOOLEAN,\\n  HASSUBSCRIBED BOOLEAN,\\n  ISBOUNCE BOOLEAN,\\n  ISSPAMTRAP BOOLEAN,\\n  ISSYNCED BOOLEAN,\\n  LASTUPDATE TIMESTAMP_NTZ(9),\\n  ORIGIN VARCHAR(16777216),'), Document(page_content='create or replace schema COUPON_PLATFORM;'), Document(page_content='create or replace schema ECOM;'), Document(page_content='primary key (ID),\\n\\tforeign key (CATEGORY_ID) references PRODUCT_CATEGORIES(ID)\\n);\\ncreate or replace TABLE PRODUCTS_DETAILS (\\n\\tPRODUCT_ID NUMBER(38,0) NOT NULL,\\n\\tPRODUCT_INFO VARIANT,\\n\\tprimary key (PRODUCT_ID)\\n);\\ncreate or replace TABLE PRODUCT_CATEGORIES (\\n\\tCATEGORY_NAME VARCHAR(255),\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tprimary key (ID)\\n);\\ncreate or replace TABLE PRODUCT_REVIEWS (\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tPRODUCT_ID NUMBER(38,0),\\n\\tRATING_STARS NUMBER(38,0),\\n\\tprimary key (ID)\\n);'), Document(page_content='PRICE NUMBER(10,2),\\n\\tQUANTITY NUMBER(38,0),\\n\\tDISCOUNT_PRICE NUMBER(10,2)\\n);\\ncreate or replace TABLE PAYMENT_TRANSACTIONS (\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tAMOUNT NUMBER(10,2),\\n\\tORDER_ID NUMBER(38,0),\\n\\tprimary key (ID)\\n);\\ncreate or replace TABLE PRODUCTS (\\n\\tPRICE NUMBER(10,2),\\n\\tCATEGORY_ID NUMBER(38,0),\\n\\tNAME VARCHAR(255),\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tPRODUCER_WEBSITE VARCHAR(255),\\n\\tprimary key (ID),\\n\\tforeign key (CATEGORY_ID) references PRODUCT_CATEGORIES(ID)\\n);'), Document(page_content='create or replace TABLE CUSTOMERS (\\n\\tZIP_CODE VARCHAR(10),\\n\\tGENDER VARCHAR(1),\\n\\tAGE NUMBER(38,0),\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tCOHORT NUMBER(38,0),\\n\\tEMAIL VARCHAR(100),\\n\\tREGISTERED_AT TIMESTAMP_NTZ(9),\\n\\tprimary key (ID)\\n);\\ncreate or replace TABLE DEPARTMENTS (\\n\\tDEPARTMENT_NAME VARCHAR(255),\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tprimary key (ID)\\n);\\ncreate or replace TABLE EMPLOYEES (\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tDEPARTMENT_ID NUMBER(38,0),\\n\\tSALARY NUMBER(10,2),\\n\\tprimary key (ID),'), Document(page_content='TOTAL_AMT NUMBER(10,2),\\n\\tCATEGORY_ID NUMBER(38,0),\\n\\tCUSTOMER_ID NUMBER(38,0),\\n\\tID NUMBER(38,0) NOT NULL,\\n\\tORDER_ID NUMBER(38,0),\\n\\tORDER_TIMESTAMP TIMESTAMP_NTZ(9),\\n\\tprimary key (ID),\\n\\tforeign key (CATEGORY_ID) references PRODUCT_CATEGORIES(ID),\\n\\tforeign key (CUSTOMER_ID) references CUSTOMERS(ID)\\n);\\ncreate or replace TABLE ORDER_LINES (\\n\\tORDER_ID NUMBER(38,0),\\n\\tPRODUCT_ID NUMBER(38,0),\\n\\tPRICE NUMBER(10,2),\\n\\tQUANTITY NUMBER(38,0),\\n\\tDISCOUNT_PRICE NUMBER(10,2)\\n);'), Document(page_content=');\\ncreate or replace TABLE NEWSVIEWS (\\n  ID NUMBER(38,0),\\n  EMAIL VARCHAR(16777216),\\n  MESSAGEID NUMBER(38,0),\\n  MESSAGENAME VARCHAR(16777216),\\n  NEWSLETTERID NUMBER(38,0),\\n  TIME TIMESTAMP_NTZ(9)\\n);\\ncreate or replace TABLE STORES (\\n  ID NUMBER(38,0),\\n  ACCOUNTID NUMBER(38,0),\\n  AFFILIATENETWORKID NUMBER(38,0),\\n  AVERAGESAVINGS FLOAT,\\n  CATEGORYID NUMBER(38,0),\\n  CREATIONDATE TIMESTAMP_NTZ(9),\\n  DESCRIPTION VARCHAR(16777216),\\n  HASADSENABLED BOOLEAN,\\n  HASALERTENABLED BOOLEAN,')]\n",
      "Question: Write an SQL query to retrieve the GPA of all students, where the GPA is stored in a separate table called gpa, \n",
      "                 and the student information is stored in a students table.\n",
      "\n",
      "Answer:\n",
      "Assuming that the students table has columns 'student_id', 'student_name', and 'gpa' and the gpa table has columns 'student_id' and 'gpa', the SQL query would be:\n",
      "\n",
      "```sql\n",
      "SELECT s.student_id, s.student_name, g.gpa\n",
      "FROM students s\n",
      "JOIN gpa g ON s.student_id = g.student\n"
     ]
    }
   ],
   "source": [
    "prompt_text = '''Write an SQL query to retrieve the GPA of all students, where the GPA is stored in a separate table called gpa, \n",
    "                 and the student information is stored in a students table.'''\n",
    "\n",
    "output = chain.invoke(prompt_text)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
